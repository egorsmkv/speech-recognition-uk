1. Для создания относительно неплохой языковой модели нам необходимо большое количество целевого текста, в зависимости от тематики распознавания (юридические, военные, дипломатические, медицинские и т.д.) это необходимо чтобы повысить вероятность определения фраз специфичных для отрасли.
Некоторые фразы типичные для медицины, очень маловероятны в военной сфере, и наоборот, поэтому повышается ошибка распознавания.
Но в общем случае достаточно будет просто большого количества текста.

1. Текст нужно почистить. Убрать различные знаки препинания, специальные символы, привести к единому регистру (верхнему, нижнему). Убрать слова, фразы предложения, которые не относятся к данному языку. Весь текст в UTF-8 
    ```
        iconv -f cp1251 -t utf8 in.txt -o out.txt
    ```
   
1. Из очищенного текста создаем arpa файл, с помощью программы srilm, для будущей языковой модели следующей командой:

   ```
        /home/user/kaldi/tools/srilm/bin/i686-m64/ngram-count -order 3 -wbdiscount -write-vocab librispeech-vocab.txt -text corpus.txt -lm lm.arpa
   где
        order – максимальная длина словосочетаний (обычно наиболее оптимально 3 или 4, 4 улучшает качество распознавания, но замедляет его);
        write-vocab – записать в файл все уникальные слова (из нее потом создадим лексикон (слово – фонемный разбор)
        text – собственно исходный очищенный текст
        lm – выходной файл для языковой модели.
   ```

    После предущей команды создастся очень большой файл с фразами и их вероятностями возникновения. Следующие команды необходимы для работы скрипта для обучения. Эти команды уменьшают размер модели удаляя маловероятные фразы флаг prune.

    ```
       /home/user/kaldi/tools/srilm/bin/i686-m64/ngram -lm lm.arpa -prune 1e-8 -write-lm lm_tglarge.arpa.gz
       /home/user/kaldi/tools/srilm/bin/i686-m64/ngram -lm lm.arpa -prune 1e-7 -write-lm lm_tgmed.arpa.gz
       /home/user/kaldi/tools/srilm/bin/i686-m64/ngram -lm lm.arpa -prune 3e-7 -write-lm lm_tgsmall.arpa.gz
   ```

1. Создаем файл с лексиконом librispeech-lexicon.txt, для этого берем все слова из ранее полученного файла librispeech-vocab.txt, и расписываем фонемы для каждого слова, или пропускаем слова через какую либо программу, которая сможет выдать фонемный разбор слов автоматически. Я нашел несколько таких (`MaryTTS, espeak-ng`).

1. На данный момент должно быть 5 файлов:
    * librispeech-vocab.txt
    * librispeech-lexicon.txt
    * lm_tglarge.arpa.gz
    * lm_tgmed.arpa.gz
    * lm_tgsmall.arpa.gz
   
1. Подготавливаем данные для акустической модели, для этого нам необходимо от 200 часов расписанных данных (аудиозапись – текст), нам необходимо подготовить следующие файлы:

    * wav.scp
    * text
    * utt2spk
    * spk2gender
    
    таких файлов должно быть 2 набора, один для тестовых данных, другой для тренировочных.
    
    ```
        wav.scp <id> <путь к аудиофайлу>
        text <id> <текст соответсвующий содержанию аудиофайла>
        utt2spk <id> <id диктора>
        spk2gender <id диктора> <m или f (m – male, f - female)>
   ```
   
   чтобы не возникало проблем я для генерации id брал путь к файлу получал хэш с помощью функции SHA-224, добавлял тире после 4-5 символа.
   Получается строка такого вида
    ``` 
        <id> 8d360-3030f67a2f95a9d59d68e29f8383ac2ce565d7ecef960e5a706
        <id диктора> = 8d360
    ```
   
1. В итоге до начала обучения должны быть следующие файлы в директории `data/local/lm`

    * librispeech-vocab.txt
    * librispeech-lexicon.txt
    * lm_tglarge.arpa.gz
    * lm_tgmed.arpa.gz
    * lm_tgsmall.arpa.gz
    
    в директории `data/dev-clean-2` – тестовые данные 5%, `data/train-clean-5` – тренировочные`
    
    * wav.scp
    * text
    * utt2spk
    * spk2gender
    
    также можно создать одну директорию `data/ukraine`, тогда в файле `my.sh` раскомментировать 
    
    ```
        # utils/fix_data_dir.sh data/ukraine
       
        # utils/subset_data_dir.sh --first data/ukraine 20000 data/dev_clean_2
        # n=$[`cat data/ukraine/text | wc -l` - 20000]
        # utils/subset_data_dir.sh --last data/ukraine $n data/train_clean_5
   ```
    
1. Заходим в директорию `kaldi/egs/`

1. Копируем директорию `mini_librispeech` c новым названием

1. Заходим в скопированной директории в директорию `s5`

1. В корень директории размещаем файлы с путями из пункта 7 структура должна получиться следующая ![структура](structure.jpg)

1. В файле `path.sh` в директории s5, поменять путь к директории со скомпилированным проектом kaldi, если необходимо 
   
   ```export KALDI_ROOT=`pwd`/../../..```
   
   на свой путь
   
   ```export KALDI_ROOT=/opt/kaldi```
   
1. run_tdnn_1j.sh поместить в папку `local/chain/tuning`

1. run_ivector_common.sh поместить в папку `local/nnet3/tuning`

1. my.sh и cmd.sh в папку s5

1. если у вас процессор не с 4 ядрами то в каждом из этих файлов замените `--nj 4` на `--nj N` – соответсвующее количеству ядер

1. после этого можно запускать файл my.sh, и если все пункты были выполнены верно, ждать успешного завершения обучения. 
   Чтобы запустить с конкретного этапа добавляем ключ --stage 3; 
   Чтобы посмотреть промежуточные показатели качества распознавания вызываем скрипт:
   `/home/user/kaldi/egs/ukraine/s5$ ./RESULTS.sh `
   
1. Запускаем скрипт `create_model.sh` – в Home появляется папка model с моделью    